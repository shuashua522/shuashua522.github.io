import{_ as s}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as a,f as e,o as t}from"./app-CQtRY0hP.js";const n="/assets/image-20251018163001758-DRlh6Cwz.png",l={};function h(p,i){return t(),a("div",null,[...i[0]||(i[0]=[e('<h2 id="gemma3" tabindex="-1"><a class="header-anchor" href="#gemma3"><span>Gemma3</span></a></h2><blockquote><p><a href="https://ollama.com/library/gemma3" target="_blank" rel="noopener noreferrer">gemma3 --- gemma3</a></p></blockquote><p>当前在单个 GPU 上运行的最强大的模型。</p><p><strong>这个模型需要 Ollama 0.6 或更高版本。</strong></p><p>Gemma 是 Google 基于 Gemini 技术构建的一家人工智能模型。Gemma 3 模型是多模态的，可以处理文本和图像，具有 128K 的上下文窗口，支持超过 140 种语言。它们有 270M、1B、4B、12B 和 27B 参数大小，擅长问答、摘要和推理等任务，而其紧凑的设计允许在资源受限的设备上部署。</p><h2 id="安装ollama" tabindex="-1"><a class="header-anchor" href="#安装ollama"><span>安装Ollama</span></a></h2><blockquote><p><a href="https://ollama.com/download" target="_blank" rel="noopener noreferrer">Download Ollama</a></p><p>安装完成后，Ollama 会自动在后台启动服务（默认端口：<code>11434</code>）</p></blockquote><p>选择gemma3:270m下载</p><figure><img src="'+n+`" alt="image-20251018163001758" tabindex="0" loading="lazy"><figcaption>image-20251018163001758</figcaption></figure><h2 id="openai-api调用" tabindex="-1"><a class="header-anchor" href="#openai-api调用"><span>openai api调用</span></a></h2><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code class="language-python"><span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">from</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> openai </span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">import</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> OpenAI</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 配置客户端，指向本地Ollama服务</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">client </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;"> OpenAI</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">    base_url</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;http://localhost:11434/v1&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># Ollama的OpenAI兼容端点</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">    api_key</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;ollama&quot;</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">  # 本地调用无需真实API密钥，任意字符串即可</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 调用Gemma3（模型名称需与下载的标签一致，如gemma3:4b）</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">response </span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;"> client.chat.completions.</span><span style="--shiki-light:#383A42;--shiki-dark:#61AFEF;">create</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">    model</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;gemma3:270m&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 模型标签（与pull/run时一致）</span></span>
<span class="line"><span style="--shiki-light:#986801;--shiki-light-font-style:inherit;--shiki-dark:#E06C75;--shiki-dark-font-style:italic;">    messages</span><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">=</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">[</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        {</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;role&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;user&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;content&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;介绍一下你自己&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">}</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    ]</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;"># 输出结果</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">print</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(response.choices[</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">0</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">].message.content)</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,11)])])}const o=s(l,[["render",h]]),m=JSON.parse('{"path":"/shua_blog/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2gemma3.html","title":"本地部署gemma3","lang":"zh-CN","frontmatter":{"title":"本地部署gemma3","icon":"pen-to-square","date":"2025-10-18T00:00:00.000Z","category":["agent"],"tag":["ollama"],"description":"Gemma3 gemma3 --- gemma3 当前在单个 GPU 上运行的最强大的模型。 这个模型需要 Ollama 0.6 或更高版本。 Gemma 是 Google 基于 Gemini 技术构建的一家人工智能模型。Gemma 3 模型是多模态的，可以处理文本和图像，具有 128K 的上下文窗口，支持超过 140 种语言。它们有 270M、1B、...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"本地部署gemma3\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2025-10-18T00:00:00.000Z\\",\\"dateModified\\":\\"2025-10-21T13:11:15.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"shuashua\\",\\"url\\":\\"https://mister-hope.com\\"}]}"],["meta",{"property":"og:url","content":"https://mister-hope.github.io/shua_blog/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2gemma3.html"}],["meta",{"property":"og:site_name","content":"shuashua的博客"}],["meta",{"property":"og:title","content":"本地部署gemma3"}],["meta",{"property":"og:description","content":"Gemma3 gemma3 --- gemma3 当前在单个 GPU 上运行的最强大的模型。 这个模型需要 Ollama 0.6 或更高版本。 Gemma 是 Google 基于 Gemini 技术构建的一家人工智能模型。Gemma 3 模型是多模态的，可以处理文本和图像，具有 128K 的上下文窗口，支持超过 140 种语言。它们有 270M、1B、..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-10-21T13:11:15.000Z"}],["meta",{"property":"article:tag","content":"ollama"}],["meta",{"property":"article:published_time","content":"2025-10-18T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2025-10-21T13:11:15.000Z"}]]},"git":{"createdTime":1760789466000,"updatedTime":1761052275000,"contributors":[{"name":"shuashua522","username":"shuashua522","email":"shuashua_world@163.com","commits":3,"url":"https://github.com/shuashua522"}]},"readingTime":{"minutes":0.98,"words":295},"filePathRelative":"shua_blog/本地部署gemma3.md","excerpt":"<h2>Gemma3</h2>\\n<blockquote>\\n<p><a href=\\"https://ollama.com/library/gemma3\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">gemma3 --- gemma3</a></p>\\n</blockquote>\\n<p>当前在单个 GPU 上运行的最强大的模型。</p>\\n<p><strong>这个模型需要 Ollama 0.6 或更高版本。</strong></p>\\n<p>Gemma 是 Google 基于 Gemini 技术构建的一家人工智能模型。Gemma 3 模型是多模态的，可以处理文本和图像，具有 128K 的上下文窗口，支持超过 140 种语言。它们有 270M、1B、4B、12B 和 27B 参数大小，擅长问答、摘要和推理等任务，而其紧凑的设计允许在资源受限的设备上部署。</p>","autoDesc":true}');export{o as comp,m as data};
